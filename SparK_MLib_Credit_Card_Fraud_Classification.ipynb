{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " SparK MLib - Credit Card Fraud Classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAQyam-QFNoG",
        "colab_type": "text"
      },
      "source": [
        "# SparK MLib - Credit Card Fraud Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tFRO-vxFUFR",
        "colab_type": "code",
        "outputId": "76e3351b-6206-4bee-c330-d6dcfb06ca68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Let's mount Google Drive So We can Retrieve the Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwVoUT7hFa4v",
        "colab_type": "code",
        "outputId": "70abaf42-8a69-4e57-fae4-1829fabdef04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#There is One File of Creit Card Data. Source  Kaggle.com\n",
        "!ls \"/content/gdrive/My Drive/CC Data/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creditcardfraud.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1bhJ2SyFo1Z",
        "colab_type": "code",
        "outputId": "a61cde11-20c1-4226-8987-afa92ba868aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Unzip the files to reveal creditcard.csv\n",
        "#!rm -r *\n",
        "!unzip -qq \"/content/gdrive/My Drive/CC Data/creditcardfraud.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace creditcard.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crNTe0bwFvQK",
        "colab_type": "code",
        "outputId": "4040ceea-abfb-4d08-95fa-2ad29e9c4e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creditcard.csv\tsample_data\t\t   spark-2.4.3-bin-hadoop2.7.tgz\n",
            "gdrive\t\tspark-2.4.3-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hExXH9mpGV5h",
        "colab_type": "text"
      },
      "source": [
        "# **Install and Load Up Spark**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj9qM0DMGWf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install Latest Version of Spark As of Current Data. 2.4.3\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jqUa9mNGa8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1l_L0E-GebH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImiT9SIOGhw1",
        "colab_type": "code",
        "outputId": "7e755c25-a50e-4587-c74d-b5ab85cef9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "df = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load('creditcard.csv').withColumnRenamed('Class', 'label')\n",
        "df.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n",
            "|Time|                V1|                 V2|              V3|                V4|                 V5|                 V6|                 V7|                V8|                V9|                V10|               V11|               V12|               V13|               V14|               V15|               V16|               V17|                V18|               V19|                V20|                 V21|                V22|               V23|               V24|               V25|               V26|                 V27|                V28|Amount|label|\n",
            "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n",
            "|   0|  -1.3598071336738|-0.0727811733098497|2.53634673796914|  1.37815522427443| -0.338320769942518|  0.462387777762292|  0.239598554061257|0.0986979012610507| 0.363786969611213| 0.0907941719789316|-0.551599533260813|-0.617800855762348|-0.991389847235408|-0.311169353699879|  1.46817697209427|-0.470400525259478| 0.207971241929242| 0.0257905801985591| 0.403992960255733|  0.251412098239705|  -0.018306777944153|  0.277837575558899|-0.110473910188767|0.0669280749146731| 0.128539358273528|-0.189114843888824|   0.133558376740387|-0.0210530534538215|149.62|    0|\n",
            "|   0|  1.19185711131486|   0.26615071205963|0.16648011335321| 0.448154078460911| 0.0600176492822243|-0.0823608088155687|-0.0788029833323113|0.0851016549148104|-0.255425128109186| -0.166974414004614|  1.61272666105479|  1.06523531137287|  0.48909501589608|-0.143772296441519| 0.635558093258208| 0.463917041022171|-0.114804663102346| -0.183361270123994|-0.145783041325259|-0.0690831352230203|  -0.225775248033138| -0.638671952771851| 0.101288021253234|-0.339846475529127| 0.167170404418143| 0.125894532368176|-0.00898309914322813| 0.0147241691924927|  2.69|    0|\n",
            "|   1| -1.35835406159823|  -1.34016307473609|1.77320934263119| 0.379779593034328| -0.503198133318193|   1.80049938079263|  0.791460956450422| 0.247675786588991| -1.51465432260583|  0.207642865216696| 0.624501459424895| 0.066083685268831| 0.717292731410831|-0.165945922763554|  2.34586494901581| -2.89008319444231|  1.10996937869599| -0.121359313195888| -2.26185709530414|  0.524979725224404|   0.247998153469754|  0.771679401917229| 0.909412262347719|-0.689280956490685|-0.327641833735251|-0.139096571514147| -0.0553527940384261|-0.0597518405929204|378.66|    0|\n",
            "|   1|-0.966271711572087| -0.185226008082898|1.79299333957872|-0.863291275036453|-0.0103088796030823|   1.24720316752486|   0.23760893977178| 0.377435874652262| -1.38702406270197|-0.0549519224713749|-0.226487263835401| 0.178228225877303| 0.507756869957169| -0.28792374549456|-0.631418117709045|  -1.0596472454325|-0.684092786345479|   1.96577500349538|  -1.2326219700892| -0.208037781160366|  -0.108300452035545|0.00527359678253453|-0.190320518742841| -1.17557533186321| 0.647376034602038|-0.221928844458407|  0.0627228487293033| 0.0614576285006353| 123.5|    0|\n",
            "|   2| -1.15823309349523|  0.877736754848451|  1.548717846511| 0.403033933955121| -0.407193377311653| 0.0959214624684256|  0.592940745385545|-0.270532677192282| 0.817739308235294|  0.753074431976354|-0.822842877946363|  0.53819555014995|   1.3458515932154| -1.11966983471731| 0.175121130008994|-0.451449182813529|-0.237033239362776|-0.0381947870352842| 0.803486924960175|  0.408542360392758|-0.00943069713232919|   0.79827849458971|-0.137458079619063| 0.141266983824769|-0.206009587619756| 0.502292224181569|   0.219422229513348|  0.215153147499206| 69.99|    0|\n",
            "+----+------------------+-------------------+----------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTRtd5LlGq4o",
        "colab_type": "code",
        "outputId": "0c6c60cb-8786-4e88-b982-56c8392dca86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Time: decimal(10,0) (nullable = true)\n",
            " |-- V1: double (nullable = true)\n",
            " |-- V2: double (nullable = true)\n",
            " |-- V3: double (nullable = true)\n",
            " |-- V4: double (nullable = true)\n",
            " |-- V5: double (nullable = true)\n",
            " |-- V6: double (nullable = true)\n",
            " |-- V7: double (nullable = true)\n",
            " |-- V8: double (nullable = true)\n",
            " |-- V9: double (nullable = true)\n",
            " |-- V10: double (nullable = true)\n",
            " |-- V11: double (nullable = true)\n",
            " |-- V12: double (nullable = true)\n",
            " |-- V13: double (nullable = true)\n",
            " |-- V14: double (nullable = true)\n",
            " |-- V15: double (nullable = true)\n",
            " |-- V16: double (nullable = true)\n",
            " |-- V17: double (nullable = true)\n",
            " |-- V18: double (nullable = true)\n",
            " |-- V19: double (nullable = true)\n",
            " |-- V20: double (nullable = true)\n",
            " |-- V21: double (nullable = true)\n",
            " |-- V22: double (nullable = true)\n",
            " |-- V23: double (nullable = true)\n",
            " |-- V24: double (nullable = true)\n",
            " |-- V25: double (nullable = true)\n",
            " |-- V26: double (nullable = true)\n",
            " |-- V27: double (nullable = true)\n",
            " |-- V28: double (nullable = true)\n",
            " |-- Amount: double (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R06aoAICG5NN",
        "colab_type": "text"
      },
      "source": [
        "Examining the table above. This data is a collection of PCA features along with an amount total and a class total."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQvSkqCAG528",
        "colab_type": "code",
        "outputId": "1e501e96-7927-4d1f-ec8f-c846e4af9a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# total amount of records is 284807\n",
        "df.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "284807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA1ejvnvHC5t",
        "colab_type": "code",
        "outputId": "59c7c7b0-a0ed-42ac-ace8-1555bcd7ed02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
            "|summary|              Time|                  V1|                  V2|                  V3|                  V4|                  V5|                  V6|                  V7|                  V8|                  V9|                 V10|                 V11|                 V12|                 V13|                 V14|                 V15|                 V16|                 V17|                 V18|                 V19|                 V20|                 V21|                 V22|                 V23|                 V24|                 V25|                 V26|                 V27|                 V28|            Amount|               label|\n",
            "+-------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
            "|  count|            284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|            284807|              284807|\n",
            "|   mean|        94813.8596|5.109395214431826...|2.554697607215913...|-8.63487791238978...|3.525482697957960...|2.043758085772730...|2.088465293899009...|-2.28645435845824...|-3.57657665010227...|-1.34121624378835...|1.900056345366835...|2.05653157380881E-15|-2.67285237154964...|7.887628862279132...|1.497691472230329...|2.707979463648868...|1.444202491079246...|-3.19337200901989...|3.640444090282676...|9.468348006743977...|1.820222045141338...|2.554697607215913...|8.941441625255696...|7.664092821647739...|4.515428020754126...|1.545592052365627...|1.737194372906821...|-3.54564085876489...|-1.31127838120379...|  88.3496192509508|0.001727485630620034|\n",
            "| stddev|47488.145954566906|  1.9586958038574882|   1.651308579476995|  1.5162550051777774|  1.4158685749409223|  1.3802467340314277|  1.3322710897575698|  1.2370935981826607|  1.1943529026691984|  1.0986320892243164|  1.0888497654025246|  1.0207130277115635|  0.9992013895301407|  0.9952742301251535|   0.958595611257067|  0.9153160116104393|  0.8762528873883741|  0.8493370636743898|  0.8381762095288434|  0.8140405007685821|  0.7709250248871147|  0.7345240143713111|  0.7257015604409144|  0.6244602955949919|   0.605647067827159|  0.5212780705409377| 0.48222701326105777|  0.4036324949650308| 0.33008326416025036|250.12010924018736| 0.04152718963546528|\n",
            "|    min|                 0|    -56.407509631329|   -72.7157275629303|   -48.3255893623954|   -5.68317119816995|   -113.743306711146|   -26.1605059358433|   -43.5572415712451|   -73.2167184552674|   -13.4340663182301|   -24.5882624372475|   -4.79747346479757|   -18.6837146333443|   -5.79188120632084|   -19.2143254902614|   -4.49894467676621|   -14.1298545174931|   -25.1627993693248|   -9.49874592104677|   -7.21352743017759|    -54.497720494566|   -34.8303821448146|    -10.933143697655|   -44.8077352037913|   -2.83662691870341|   -10.2953970749851|   -2.60455055280817|   -22.5656793207827|   -15.4300839055349|               0.0|                   0|\n",
            "|    max|            172792|    2.45492999121121|    22.0577289904909|    9.38255843282114|    16.8753440335975|    34.8016658766686|    73.3016255459646|    120.589493945238|    20.0072083651213|    15.5949946071278|    23.7451361206545|    12.0189131816199|     7.8483920756446|    7.12688295859376|    10.5267660517847|    8.87774159774277|    17.3151115176278|    9.25352625047285|    5.04106918541184|    5.59197142733558|    39.4209042482199|    27.2028391573154|    10.5030900899454|    22.5284116897749|    4.58454913689817|    7.51958867870916|     3.5173456116238|    31.6121981061363|    33.8478078188831|          25691.16|                   1|\n",
            "+-------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wklef_yyS1nq",
        "colab_type": "code",
        "outputId": "ef5d56a7-a728-4865-d451-80ea7264386a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "#check missing values for each column\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "\n",
        "df.select([count(when(isnan(column), column)).alias('MV') for column in df.columns]).show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
            "| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV| MV|\n",
            "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
            "|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
            "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dw78pIhHYeC",
        "colab_type": "code",
        "outputId": "0c0ec433-f8cc-439a-fdad-878d5d6a83ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#Lets Check the distribution of the class feature. Note  0 = No Fraud, while 1 = Fraud\n",
        "df.groupby('label').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|label| count|\n",
            "+-----+------+\n",
            "|    1|   492|\n",
            "|    0|284315|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUdaVhdBKMf9",
        "colab_type": "text"
      },
      "source": [
        "###Unbalanced Class Problem\n",
        "As you can see above, the fraud class (1) is only 492 records out to the 284315. This is a class unbalanced class situation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfdSw1iIU8Sz",
        "colab_type": "code",
        "outputId": "7fead244-9949-4b4b-dca7-417facb627f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Split the data train vs test\n",
        "\n",
        "weights = [.8, .2]  #80% Train, 20% Test given the unbalanced nature of the data\n",
        "seed = 42\n",
        "dfTrain, dfTest = df.randomSplit(weights, seed)\n",
        "dfTrain.cache(), dfTest.cache()  #IMPORTANT TO CACHE!!!!\n",
        "dfTrain.count(), dfTest.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(228135, 56672)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKd_Qeg3U5gn",
        "colab_type": "text"
      },
      "source": [
        "# Running A Model On the Unbalanced Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ziDdkrCViON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Logistic Regression Model\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression().setLabelCol(\"label\")\n",
        "paramMap = {lr.maxIter: 10, lr.regParam: .1, lr.elasticNetParam: 0.01}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SdyZaSfWEUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All our features are numberical, we can use VectorAssembler right away to create a feature vector that Spark needs\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "#assemble our features\n",
        "IntFeat = df.columns[1:31]\n",
        "assembler = VectorAssembler(inputCols= IntFeat, outputCol = \"features\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHYRWyZrYKSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[assembler] + [lr])\n",
        "model_Train = pipeline.fit(dfTrain, paramMap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJV500eFZC92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run the model on the Test Data (holdout)\n",
        "\n",
        "output = model_Train.transform(dfTest).select(\"features\",\"label\", \"prediction\", \"rawPrediction\", \"probability\")\n",
        "prediction = output.select(\"label\", \"prediction\", \"rawPrediction\", )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz-rxYGwb_Cu",
        "colab_type": "code",
        "outputId": "454a59b1-ed8b-40e6-daa3-20fd368d6ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
        "metric = evaluator.evaluate(prediction)\n",
        "print(\"Accuracy = %s\" % metric)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9987648221343873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNQvjjLddecU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Keep in mind, given the unbalanced class, a high accuracy means the model is good at predicting the non fraud class. But what about the fraud class?\n",
        "#Run a confusion matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAH59ucIgSr7",
        "colab_type": "code",
        "outputId": "fdb8c286-1049-4e4f-c5c4-109facacd77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Metrics\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "predRDD = prediction.select('label', 'prediction').withColumn(\"label\", prediction.label.cast('float')).rdd\n",
        "metrics = BinaryClassificationMetrics(predRDD)\n",
        "\n",
        "print(\"Summary Stats:\")\n",
        "print(\"Area Under Presion Recall = %s\" %  metrics.areaUnderPR)\n",
        "print(\"Area Under ROC = %s\" % metrics.areaUnderROC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary Stats:\n",
            "Area Under Presion Recall = 0.34579439252336447\n",
            "Area Under ROC = 0.9993820075924781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps-fCCk5X0oE",
        "colab_type": "code",
        "outputId": "bd5a40a2-81ff-499d-a607-7b41a5f2020b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#The above scores for accuracy and Area Under ROC look good, however, when we look at Area Under PR, the results are quite poor.\n",
        "#This is not a suprise when your classes are heavily unbalanced. Looking at the actual Class vs predected class.\n",
        "#This model only classifies only 30% of true fraud cases. We can do better.\n",
        "\n",
        "prediction.crosstab(\"label\", 'prediction').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-----+---+\n",
            "|label_prediction|  0.0|1.0|\n",
            "+----------------+-----+---+\n",
            "|               1|   70| 37|\n",
            "|               0|56565|  0|\n",
            "+----------------+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MQaGcUcaju_",
        "colab_type": "text"
      },
      "source": [
        "# Running A Model On a More Balanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amCCGHnpKurX",
        "colab_type": "text"
      },
      "source": [
        "###What to do about Unbalanced Class problem?\n",
        "Generall, there are a number of things you can do to help aleviate the problem such trying different algorithms, collecting more data, sub-sampling the majority class, over-sampling the minority class, etc... In this example, we are going to over-weight the loss function towards the minority class. This should provide a more robust model. The function below was inspired by the following post...\n",
        "\n",
        "https://stackoverflow.com/questions/33372838/dealing-with-unbalanced-datasets-in-spark-mllib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-FscmthjYD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets increase the balance among classes\n",
        "\n",
        "#from pyspark.sql.functions import udf\n",
        "\n",
        "def balanceDataset(DataFrame, String = \"label\"):\n",
        "  datasetSize= DataFrame.count()                                       \n",
        "  positives = DataFrame.filter(dfTrain.label == 1).count()\n",
        "  balancingRatio = positives/datasetSize\n",
        "  weighteddfTrain = DataFrame.withColumn(\"classWeightCol\", (when(col(\"label\") == 1, 1 - balancingRatio).otherwise(balancingRatio)))\n",
        "  return weighteddfTrain\n",
        "  \n",
        "#spark.udf.register(\"BalanceDataset\", balanceDataset)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9AoyDsskXJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "\n",
        "weightedDatasetdf= balanceDataset(dfTrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "You20P3TXj_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Logistic Regression Model\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression().setWeightCol('classWeightCol').setLabelCol(\"label\")\n",
        "#paramMap = {lr.maxIter: 10, lr.regParam: .1, lr.elasticNetParam: 0.01}\n",
        "paramMap = {lr.maxIter: 5, lr.regParam: .05, lr.elasticNetParam: 0.05}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCTJ4kObobHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All our features are numberical, we can use VectorAssembler right away to create a feature vector that Spark needs\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "#assemble our features\n",
        "IntFeat = weightedDatasetdf.columns[1:30]\n",
        "assembler = VectorAssembler(inputCols= IntFeat, outputCol = \"features\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9RuWvsaogsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[assembler] + [lr])\n",
        "model_Train = pipeline.fit(weightedDatasetdf, paramMap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNbDnHm5ozO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run the model on the Test Data (holdout)\n",
        "weightedDatasetdftest= balanceDataset(dfTest)\n",
        "\n",
        "output = model_Train.transform(weightedDatasetdftest).select(\"features\",\"label\", \"prediction\", \"rawPrediction\", \"probability\")\n",
        "prediction = output.select(\"label\", \"prediction\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZQ8X_OtmYe",
        "colab_type": "code",
        "outputId": "f2124774-dc94-4714-8d4d-b883134453e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
        "metric = evaluator.evaluate(prediction)\n",
        "print(\"Accuracy = %s\" % metric)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9946710897797855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1qoe9KEs-8B",
        "colab_type": "code",
        "outputId": "52fa4ad2-2e35-49e9-e67d-0928b50b0707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Metrics\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "predRDD = prediction.select('label', 'prediction').withColumn(\"label\", prediction.label.cast('float')).rdd\n",
        "metrics = BinaryClassificationMetrics(predRDD)\n",
        "\n",
        "print(\"Summary Stats:\")\n",
        "print(\"Area Under Presion Recall = %s\" %  metrics.areaUnderPR)\n",
        "print(\"Area Under ROC = %s\" % metrics.areaUnderROC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary Stats:\n",
            "Area Under Presion Recall = 0.5367959175490737\n",
            "Area Under ROC = 0.6212388001770046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDYuaK_NtB27",
        "colab_type": "code",
        "outputId": "e2664dbe-7f23-431a-ae82-966787fd755f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "prediction.crosstab(\"label\", 'prediction').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-----+---+\n",
            "|label_prediction|  0.0|1.0|\n",
            "+----------------+-----+---+\n",
            "|               1|   15| 92|\n",
            "|               0|56278|287|\n",
            "+----------------+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD4eXuBpJaA0",
        "colab_type": "text"
      },
      "source": [
        "Using weighted col in the logisitc regression model significantly improve our accuracy with respect to the fraud class!! Area under the jumps to .61 from .35. All good results. Can we improve by using cross validation and a grid search for hyperparamters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjV15t1-KEvR",
        "colab_type": "text"
      },
      "source": [
        "# Adding Cross-Validation and Grid Search for Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV46MAlpuAYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from  pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "#assemble our features\n",
        "\n",
        "cvevaluator = BinaryClassificationEvaluator(metricName = 'areaUnderPR')  #can select metric to evaluate\n",
        "cvparamGrid = ParamGridBuilder().addGrid(cvlr.maxIter, [2]).addGrid(cvlr.regParam, [.001, .05, .1, .2])\\\n",
        ".addGrid(cvlr.elasticNetParam, [.0001, .01, .05, .1]).build()\n",
        "\n",
        "numFolds=2\n",
        "\n",
        "crossval = CrossValidator(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=cvparamGrid,\n",
        "    evaluator=cvevaluator,\n",
        "    numFolds=numFolds)\n",
        "\n",
        "cvModel = crossval.fit(weightedDatasetdf)\n",
        "\n",
        "#cvPrediction = cvModel.transform(weightedDatasetdftest).select(\"label\", \"prediction\")\n",
        "cvPrediction = cvModel.transform(weightedDatasetdftest).select(\"label\", \"prediction\")\n",
        "\n",
        "#Note: Automatically selects best model, if you would like to see bestmodel then:\n",
        "bestModel = cvModel.bestModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8cYUJlmPW3e",
        "colab_type": "code",
        "outputId": "223ec547-d673-453b-d46c-e4d34880020d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cvPrediction = output.select(\"label\", \"prediction\")\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
        "metric = evaluator.evaluate(cvPrediction)\n",
        "print(\"Accuracy = %s\" % metric)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9946710897797855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U5oVsqnNQ9u",
        "colab_type": "code",
        "outputId": "57c065d1-6c50-42af-cfda-7967cbef5948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Metrics\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "predRDD = cvPrediction.select('label', 'prediction').withColumn(\"label\", cvPrediction.label.cast('float')).rdd\n",
        "metrics = BinaryClassificationMetrics(predRDD)\n",
        "\n",
        "print(\"Summary Stats:\")\n",
        "print(\"Area Under Presion Recall = %s\" %  metrics.areaUnderPR)\n",
        "print(\"Area Under ROC = %s\" % metrics.areaUnderROC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary Stats:\n",
            "Area Under Presion Recall = 0.5367959175490737\n",
            "Area Under ROC = 0.6212388001770046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3K7MT1oP8GN",
        "colab_type": "code",
        "outputId": "e25d291a-c5fd-44c3-a6a4-c39d30419d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "pcvPrediction.crosstab(\"label\", 'prediction').show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-----+---+\n",
            "|label_prediction|  0.0|1.0|\n",
            "+----------------+-----+---+\n",
            "|               1|   15| 92|\n",
            "|               0|56278|287|\n",
            "+----------------+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhDk11xgQYay",
        "colab_type": "code",
        "outputId": "f5b158dd-db9f-4195-b2f8-773aacf0d318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "SbestModel = bestModel.stages[1]\n",
        "bestParams = SbestModel.extractParamMap()\n",
        "bestParams"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{Param(parent='LogisticRegression_f92809a0413e', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent='LogisticRegression_f92809a0413e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.1, Param(parent='LogisticRegression_f92809a0413e', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.'): 'auto', Param(parent='LogisticRegression_f92809a0413e', name='featuresCol', doc='features column name'): 'features', Param(parent='LogisticRegression_f92809a0413e', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent='LogisticRegression_f92809a0413e', name='labelCol', doc='label column name'): 'label', Param(parent='LogisticRegression_f92809a0413e', name='maxIter', doc='maximum number of iterations (>= 0)'): 2, Param(parent='LogisticRegression_f92809a0413e', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='LogisticRegression_f92809a0413e', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability', Param(parent='LogisticRegression_f92809a0413e', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction', Param(parent='LogisticRegression_f92809a0413e', name='regParam', doc='regularization parameter (>= 0)'): 0.2, Param(parent='LogisticRegression_f92809a0413e', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent='LogisticRegression_f92809a0413e', name='threshold', doc='threshold in binary classification prediction, in range [0, 1]'): 0.5, Param(parent='LogisticRegression_f92809a0413e', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06, Param(parent='LogisticRegression_f92809a0413e', name='weightCol', doc='weight column name. If this is not set or empty, we treat all instance weights as 1.0'): 'classWeightCol'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD7HNcWXcJpy",
        "colab_type": "code",
        "outputId": "e9dd3915-36d3-4bb6-8fe8-612fba24497c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "cvmodel.params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-1d208002c7d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcvmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cvmodel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJvKme9eQzQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}